{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this tutorial we continue our journey in deep learning by looking at convolutional neural networks or ConvNets.\n",
    "\n",
    "Run the notebook in Google colab:\n",
    "https://colab.research.google.com/github/heprom/cvml/blob/main/tutorials/CNN.ipynb\n",
    "\n",
    "You should use GPU acceleration to train your network, on google colab, before starting working, go to Execution -> Modifier le Type d'Execution -> select GPU as hardware accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding convolutions\n",
    "\n",
    "In thisfirst section, we experiment convolutions on images using simple `numpy` operations. We first work with a single channel image from MNIST and then a 3 channel RGB image of a cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a variable `image` to hold the first $8\\times8$ image in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ...\n",
    "print(image)\n",
    "plt.imshow(..., cmap=cm.gray_r)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the following $3\\times 3$ kernel as a numpy array: $\\left[\\begin{array}{ccc}-1 & 0 & +1 \\\\ -2 & 0 & +2 \\\\ -1 & 0 & +1\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array(...)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad the image with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = ...\n",
    "pad = ...\n",
    "im = np.pad(image, ((pad, pad), (pad, pad)), mode='constant')\n",
    "print('paded image size is now {}'.format(im.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convolve the kernel with the image. Create an algorithm using for loops to output the convolution to a new variable `conv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = np.empty_like(image)\n",
    "\n",
    "for i in range(pad, im.shape[0] - pad):\n",
    "    for j in range(pad, im.shape[1] - pad):\n",
    "        subset = im[i-pad:i+pad+1, j-pad:j+pad+1]\n",
    "        conv[i-pad, j-pad] = ...  # element-wise multiplication\n",
    "\n",
    "print('output size of the convolution is {}'.format(conv.shape))\n",
    "plt.imshow(conv, cmap=cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now this works, make a function called `convolve` which takes for input an image, a kernel and output the result of the convolution. Assume image is in form (n x m x channels) and represented by floats in the [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(image, kernel):\n",
    "    kernel_size = ...\n",
    "    pad = ...\n",
    "    im = np.pad(image, ((pad, pad), (pad, pad)), mode='constant')\n",
    "    conv = np.empty_like(image)\n",
    "\n",
    "    for i in range(pad, im.shape[0] - pad):\n",
    "        for j in range(pad, im.shape[1] - pad):\n",
    "            # get the (i, j) subset of size (2 x pad + 1)\n",
    "            subset = im[i - pad:i + pad + 1, j - pad:j + pad + 1]\n",
    "            # perform the convolution\n",
    "            conv[i - pad, j - pad] = ...\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(convolve(image, kernel), cmap=cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's work with a 3 channel RGB image. Load it, convert if to float representation and in gray scale mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "cat = data.chelsea().astype(np.float)\n",
    "cat = ...  # convert to gray scale\n",
    "cat /= cat.max()  # with float representation, the range is [0, 1]\n",
    "print(cat.shape)\n",
    "print(cat.dtype)\n",
    "print(cat.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cat, cmap=cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create all the following kernel and try them out:\n",
    "\n",
    " - Blur kernel: $\\left[\\begin{array}{ccc}1 & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1\\end{array}\\right]$\n",
    " - Laplacian kernel: $\\left[\\begin{array}{ccc}0 & 1 & 0 \\\\ 1 & -4 & 1 \\\\ 0 & 1 & 0\\end{array}\\right]$\n",
    " - Emboss kernel: $\\left[\\begin{array}{ccc}-2 & -1 & 0 \\\\ -1 & 1 & 1 \\\\ 0 & 1 & 2\\end{array}\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur filters\n",
    "blur3 = ...\n",
    "blur5 = ...\n",
    "blur7 = ...\n",
    "\n",
    "# sharpen\n",
    "sharpen = ...\n",
    "\n",
    "# Laplacian kernel\n",
    "laplacian = ...\n",
    "\n",
    "# construct an emboss kernel\n",
    "emboss = ...\n",
    "\n",
    "kernels = [blur3, sharpen, laplacian, emboss]\n",
    "kernel_labels = ['blur3', 'sharpen', 'laplacian', 'emboss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "for i in range(len(kernels)):\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    convolution = ...\n",
    "    plt.imshow(convolution, cmap=cm.gray, vmin=0.6, vmax=0.9)\n",
    "    plt.title(kernel_labels[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First ConvNet: ShallowNet architecture\n",
    "\n",
    "This model only contains a few layers, so it is perfect to get started with CNN. The architecture can be summarized as:\n",
    "\n",
    "```INPUT => CONV => RELU => FC```\n",
    "\n",
    "### As usual start by loading our data set\n",
    "\n",
    "Here we will work with animals JPG pictures with 3 classes: cats, dogs and panda, observe that the data has been preprocessed to crop and resize them to a fixed size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['cats', 'dogs', 'panda']\n",
    "data = np.load('animals.npz')\n",
    "print(data['X'].shape)\n",
    "print(data['y'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a random image to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(...)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data into training and testing splits using 75% of the data for training and the remaining 25% for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the labels from integers to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_test = LabelBinarizer().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some sanity checks\n",
    "print(y_train.dtype)\n",
    "print(X_test[0].shape)\n",
    "print(y_train[0])\n",
    "print(y_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model with Keras\n",
    "\n",
    "start importing useful stuff from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the optimizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# define the first (and only) CONV => RELU layer\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=...))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# softmax classifier after a FC layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(...))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "print('compiling model')\n",
    "opt = SGD(lr=0.005)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=opt, \n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using 100 epochs and a mini batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training network')\n",
    "H = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    batch_size=..., \n",
    "    epochs=..., \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our model to the disk (to reuse it later), this is called **serialization**. In Keras, the architecture of the model and the trained weights are save to a HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_shallow_cnn.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the network using the method `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 4\n",
    "plt.imshow(X_test[index])\n",
    "plt.title('predicted ad %s' % labels[predictions[index].argmax()])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.figure()\n",
    "plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title('Training Loss and Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Deeper ConvNet for CIFAR-10\n",
    "\n",
    "Finally for this tutorial we try this a deeper CNN with the rather difficult CIFAR-10 data set. We will see that we can reach > 80% accuracy which is much better that previous attempts we did.\n",
    "\n",
    "As a side note, with much deeper networks (outside the scope of this tutorial since they need GPu hardware to train), it is *relatively easy* to acheive >90% (and even 95%) precision on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float') / 255.0\n",
    "X_test = X_test.astype('float') / 255.0\n",
    "labels = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'boat', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the labels from integers to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the bells and whistles we need from from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the optimizer and model, the first series of CONF has 32 filters, the second 64. The kernel sizes are (3, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first CONV (32 filters) => RELU => CONV => RELU => POOL layer set\n",
    "model.add(Conv2D(..., ..., padding='same', input_shape=...))\n",
    "model.add(...)  # activation\n",
    "model.add(...)  # BN\n",
    "model.add(Conv2D(..., ..., padding='same'))\n",
    "model.add(...)  # activation\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# second CONV (64 filters) => RELU => CONV => RELU => POOL layer set\n",
    "model.add(Conv2D(..., ..., padding='same'))\n",
    "model.add(...)  # activation\n",
    "model.add(...)  # BN\n",
    "model.add(Conv2D(..., ..., padding='same'))\n",
    "model.add(...)  # activation\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# first (and only) set of FC (512 neurons) => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(...)\n",
    "model.add(...)  # activation\n",
    "model.add(...)  # BN\n",
    "model.add(...)  # 50% dropout\n",
    "\n",
    "# softmax classifier for the 10 classes\n",
    "model.add(...)\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile our model with SGD + Momentum, crossentropy loss and use accuracy as our metric. use a learning rate of 0.01 and learning rate decay (40 epochs). Use the usual value for momentum and activate nesterov acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=..., decay=..., momentum=..., nesterov=...)\n",
    "model.compile(\n",
    "    loss=...,\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using 40 epochs and a mini batch size of 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit(\n",
    "    ..., \n",
    "    ..., \n",
    "    validation_data=(X_test, y_test), \n",
    "    batch_size=64, \n",
    "    epochs=...,  # should go to 40 if possible\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our trained model to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('miniVGGnet_cifar10.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.figure()\n",
    "plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title('Training Loss and Accuracy on CIFAR-10')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally label a few images with their prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "M = 4\n",
    "indices = np.random.randint(0, y_test.shape[0], size=N*M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "for i in range(N * M):\n",
    "    ax = plt.subplot(M, N, i + 1)\n",
    "    plt.imshow(X_test[indices[i]])\n",
    "    plt.axis('off')\n",
    "    plt.title('%s' % labels[predictions[indices[i]].argmax()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
