{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aA5ZumfmUxE2"
   },
   "source": [
    "# OCR with Keras, TensorFlow, and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOF1CYSax8A7"
   },
   "source": [
    "## import packages and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABKPObrwxrz8"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XSuVvEyyBoX"
   },
   "outputs": [],
   "source": [
    "def load_az_dataset():\n",
    "    a = np.load('sample_data/A_Z_Handwritten_Data.npz')\n",
    "    labels = ...\n",
    "    data = ... .reshape((labels.shape[0], 28, 28)).astype(np.float32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qi_u9NcyID2"
   },
   "outputs": [],
   "source": [
    "def load_mnist_dataset():\n",
    "    # load the MNIST dataset and stack the training data and testing\n",
    "    # data together (we'll create our own training and testing splits\n",
    "    # later in the project)\n",
    "    (trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
    "    data = np.vstack([trainData, testData])\n",
    "    labels = np.hstack([trainLabels, testLabels])\n",
    "    # return a 2-tuple of the MNIST data and labels\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzeU1mkgyYKi"
   },
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "#from pyimagesearch.models import ResNet\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt, matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NsEXKo5ycIo",
    "outputId": "64d374bc-24ef-4018-849a-36255529893a"
   },
   "outputs": [],
   "source": [
    "# load the A-Z dataset\n",
    "print(\"[INFO] loading A-Z dataset...\")\n",
    "azData, azLabels = load_az_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eoOrTwTyg42",
    "outputId": "1a5e8987-099f-41bc-a211-bca7263f2e3d"
   },
   "outputs": [],
   "source": [
    "# load the MNIST dataset\n",
    "print(\"[INFO] loading 0-9 dataset...\")\n",
    "digitsData, digitsLabels = load_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "z6H3EMZ1yw5-",
    "outputId": "07bfe746-a0f5-4f0f-bba2-a9a223cafdb8"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(digitsData[0], cmap=cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "e5s6xZiry1hm",
    "outputId": "5c57a3ff-1fad-4041-d8a0-52f8a93f3833"
   },
   "outputs": [],
   "source": [
    "plt.imshow(azData[0], cmap=cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWsXebpYYjaN"
   },
   "source": [
    "## Prepare the data for ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ey9-ivVAXTS6"
   },
   "outputs": [],
   "source": [
    "# the MNIST dataset occupies the labels 0-9, so let's add 10 to every\n",
    "# A-Z label to ensure the A-Z characters are not incorrectly labeled\n",
    "# as digits\n",
    "azLabels += ...\n",
    "\n",
    "# stack the A-Z data and labels with the MNIST digits data and labels\n",
    "data = np.vstack([azData, digitsData])\n",
    "labels = np.hstack([azLabels, digitsLabels])\n",
    "\n",
    "# each image in the A-Z and MNIST digts datasets are 28x28 pixels;\n",
    "# however, the architecture we're using is designed for 32x32 images,\n",
    "# so we need to resize them to 32x32\n",
    "data = [cv2.resize(image, (...)) for image in data]\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "\n",
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "data = np.expand_dims(data, axis=-1)\n",
    "data /= ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "-8iO0rlSXlxE",
    "outputId": "2864a06f-db0d-4e2c-b6cd-d112516e8cc9"
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "plt.imshow(np.squeeze(data[0]), cmap=cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nrw-FBc8Ajyf"
   },
   "source": [
    "Use 1-hot encoding for the data: each label is tranformed into a 36 components vector with a 1 at the position of the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6EwGNU_XpvD",
    "outputId": "63fd6bbc-c1c1-4155-8d11-ea8ae2c41d29"
   },
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "le = LabelBinarizer()\n",
    "labels = le.fit_transform(labels)\n",
    "print(labels[0])  # correspond to A\n",
    "counts = labels.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fII9BPTXz0W",
    "outputId": "0c9eab8b-70b5-4e71-94bb-29f44145304c"
   },
   "outputs": [],
   "source": [
    "# account for skew in the labeled data\n",
    "classTotals = labels.sum(axis=0)\n",
    "print(classTotals)\n",
    "classWeight = {}\n",
    "\n",
    "# loop over all classes and calculate the class weight\n",
    "for i in range(0, len(classTotals)):\n",
    "    classWeight[i] = classTotals.max() / classTotals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_wZ65JjX2mY"
   },
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFJjP-K9csDW"
   },
   "outputs": [],
   "source": [
    "# define the list of label names\n",
    "labelNames = \"0123456789\"\n",
    "labelNames += \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "labelNames = [l for l in labelNames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjxgzxipX6Kx"
   },
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.05,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=False,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pF8a7DiYv6Y"
   },
   "source": [
    "## ResNet model implementation with keras and tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wlN-r86YiI_"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6PDwReoZ5Ud"
   },
   "source": [
    "Model parameters: number of Epochs, initial learning rate and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFpt7ajFZ3pF"
   },
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "EPOCHS = 50\n",
    "# initial learning rate\n",
    "INIT_LR = 1e-1\n",
    "# batch size\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwoDS20YZQ5I"
   },
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "\n",
    "    @staticmethod\n",
    "    def residual_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        \n",
    "        # the shortcut branch of the ResNet module should be initialize as the input (identity) data\n",
    "        shortcut = data\n",
    "        \n",
    "        # the first block of the ResNet module are the 1x1 CONVs\n",
    "        bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
    "        act1 = Activation(\"relu\")(bn1)\n",
    "        conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "        \n",
    "        # the second block of the ResNet module are the 3x3 CONVs\n",
    "        bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
    "        act2 = Activation(\"relu\")(bn2)\n",
    "        conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride, padding=\"same\", \n",
    "                       use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
    "        \n",
    "        # the third block of the ResNet module is another set of 1x1 CONVs\n",
    "        bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
    "        act3 = Activation(\"relu\")(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
    "        \n",
    "        # if we are to reduce the spatial size, apply a CONV layer to the shortcut\n",
    "        if red:\n",
    "            shortcut = Conv2D(K, (1, 1), strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "        \n",
    "        # add together the shortcut and the final CONV\n",
    "        x = add([conv3, shortcut])\n",
    "        \n",
    "        # return the addition as the output of the ResNet module\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9, dataset=\"cifar\"):\n",
    "        \n",
    "        # initialize the input shape to be \"channels last\" and the channels dimension itself\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        # if we are using \"channels first\", update the input shape and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "        \n",
    "        # set the input and apply BN\n",
    "        inputs = Input(shape=inputShape)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(inputs)\n",
    "        \n",
    "        # check if we are utilizing the CIFAR dataset\n",
    "        if dataset == \"cifar\":\n",
    "            # apply a single CONV layer\n",
    "            x = Conv2D(filters[0], (3, 3), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
    "        \n",
    "        # loop over the number of stages\n",
    "        for i in range(0, len(stages)):\n",
    "            # initialize the stride, then apply a residual module used to reduce the spatial size of the input volume\n",
    "            stride = (1, 1) if i == 0 else (2, 2)\n",
    "            x = ResNet.residual_module(x, filters[i + 1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "        \n",
    "            # loop over the number of layers in the stage\n",
    "            for j in range(0, stages[i] - 1):\n",
    "                # apply a ResNet module\n",
    "                x = ResNet.residual_module(x, filters[i + 1], (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "        \n",
    "        # apply BN => ACT => POOL\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = AveragePooling2D((8, 8))(x)\n",
    "        \n",
    "        # softmax classifier\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "        \n",
    "        # create the model\n",
    "        model = Model(inputs, x, name=\"resnet\")\n",
    "        \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeHZ-DHYJ_I_"
   },
   "source": [
    "Note that we use a learning rate schedule here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-Edn5AVZUcN",
    "outputId": "9f4f1679-ca5e-4a8b-db94-e3c89f562d65"
   },
   "outputs": [],
   "source": [
    "# initialize and compile our deep neural network\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = ResNet.build(32, 32, 1, len(le.classes_), (3, 3, 3), (64, 64, 128, 256), reg=0.0005)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaUiP1zmuuLM"
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQWnhPISZaXr",
    "outputId": "6e607431-193c-4e19-9b89-da9cc22bee78"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(\n",
    "    aug.flow(..., ..., batch_size=...),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,\n",
    "    class_weight=classWeight,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFmbihx2kAKN",
    "outputId": "b16c54fe-c660-43cd-b6db-e1ded7823134"
   },
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] saving network to the disk\")\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/ResNet_model.h5', save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "A18u9McCkOFy",
    "outputId": "698ceffc-882a-4e93-acf3-fa37c8ff2fe0"
   },
   "outputs": [],
   "source": [
    "# construct a plot that plots and saves the training history\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.figure()\n",
    "plt.plot(N, H.history['loss'], label='training loss')\n",
    "plt.plot(N, H.history['val_loss'], label='validation loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8ZKP52hEWO3"
   },
   "source": [
    "## Evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RE9rJ5Q4ctkC",
    "outputId": "8c28ec96-8cab-4841-d20a-7bd9aa5770cd"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=labelNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPy7iDMyDtlM"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZoFulOIUJ6tm"
   },
   "outputs": [],
   "source": [
    "# normalized confusion matrix\n",
    "row_sums = conf.sum(axis=1)\n",
    "norm_conf = conf / row_sums\n",
    "\n",
    "# error rates matrix\n",
    "err_rates_matrix = conf / conf.sum(axis=1, keepdims=1)\n",
    "np.fill_diagonal(err_rates_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "86Kb1fkcI6dP",
    "outputId": "b0aa6ad1-c395-4aed-9efe-9320dac7f798"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(norm_conf)\n",
    "plt.xlabel('predicted class')\n",
    "plt.ylabel('actual class')\n",
    "plt.title('confusion matrix')\n",
    "plt.subplot(122)\n",
    "plt.imshow(err_rates_matrix)\n",
    "plt.xlabel('predicted class')\n",
    "plt.ylabel('actual class')\n",
    "plt.title('confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAPjNKFpu0Lu"
   },
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS2MOmV_vnkc"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/ResNet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJm3sY93v8R8",
    "outputId": "ba10dc12-99b5-4124-aba1-fd9be75629db"
   },
   "outputs": [],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JD5e1w388cPd",
    "outputId": "e5549f8c-9851-4bfd-e1f7-b4c3a2d29aae"
   },
   "outputs": [],
   "source": [
    "model.predict(testX[np.newaxis, 4]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "ySFccMT67X5q",
    "outputId": "b3ba1501-5f09-4f2e-9b50-9f867b80cb50"
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(testY.shape[0])\n",
    "plt.imshow(np.squeeze(testX[i]), cmap=cm.gray_r)\n",
    "plt.title('prediction: %s' % labelNames[model.predict(testX[np.newaxis, i]).argmax(axis=1)[0]])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feCSTI2Bv-TL",
    "outputId": "7d23543a-3adf-4b5e-f8f9-941e9ef929d0"
   },
   "outputs": [],
   "source": [
    "# initialize our list of output test images\n",
    "images = []\n",
    "\n",
    "# randomly select a few testing characters\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(49,)):\n",
    "    # classify the character\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "    # extract the image from the test data and initialize the text\n",
    "    image = (testX[i] * 255).astype('uint8')\n",
    "    # label color as green (correct)\n",
    "    color = (0, 255, 0)\n",
    "    # otherwise, the class label prediction is incorrect\n",
    "    if prediction[0] != np.argmax(testY[i]):\n",
    "      color = (0, 0, 255)\n",
    "    # merge the channels into one image, resize the image from 32x32\n",
    "    # to 96x96 so we can better see it and then draw the predicted\n",
    "    # label on the image\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, color, 2)\n",
    "    # add the image to our list of output images\n",
    "    images.append(image)\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWPjsfsV_wss"
   },
   "outputs": [],
   "source": [
    "def image_mosaic(image_list, image_shape, montage_shape):\n",
    "    image_montages = []\n",
    "    # start with black canvas to draw images onto\n",
    "    montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),\n",
    "                          dtype=np.uint8)\n",
    "    cursor_pos = [0, 0]\n",
    "    start_new_img = False\n",
    "    for img in image_list:\n",
    "        start_new_img = False\n",
    "        img = cv2.resize(img, image_shape)\n",
    "        # draw image to black canvas\n",
    "        montage_image[cursor_pos[1]:cursor_pos[1] + image_shape[1], cursor_pos[0]:cursor_pos[0] + image_shape[0]] = img\n",
    "        cursor_pos[0] += image_shape[0]  # increment cursor x position\n",
    "        if cursor_pos[0] >= montage_shape[0] * image_shape[0]:\n",
    "            cursor_pos[1] += image_shape[1]  # increment cursor y position\n",
    "            cursor_pos[0] = 0\n",
    "            if cursor_pos[1] >= montage_shape[1] * image_shape[1]:\n",
    "                cursor_pos = [0, 0]\n",
    "                image_montages.append(montage_image)\n",
    "                # reset black canvas\n",
    "                montage_image = np.zeros(shape=(image_shape[1] * (montage_shape[1]), image_shape[0] * montage_shape[0], 3),\n",
    "                                      dtype=np.uint8)\n",
    "                start_new_img = True\n",
    "    if start_new_img is False:\n",
    "        image_montages.append(montage_image)  # add unfinished montage\n",
    "    return image_montages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "HFBsbQqq6eNs",
    "outputId": "669f9070-e991-40f0-a928-f1a01555e6e1"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# construct the mosaic with the images\n",
    "mosaic = image_mosaic(images, (96, 96), (7, 7))[0]\n",
    "# show the output montage\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(mosaic)\n",
    "plt.title('OCR Results')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pLic9ZoGW9_"
   },
   "source": [
    "## Test on a real world image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "RSUrJb9ZAA6i",
    "outputId": "84646a5f-e4ca-410a-ed0d-d7d6014f8dd8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# load the input image from disk, convert it to grayscale, and blur\n",
    "# it to reduce noise\n",
    "image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/image_OCR9.jpg')\n",
    "image = cv2.resize(image, (int(image.shape[1] * 0.25), int(image.shape[0] * 0.25)))\n",
    "print(image.shape)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "plt.imshow(blurred, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "okBA1SD3GiTn",
    "outputId": "75eedd51-4c10-4e74-ea95-7b55e8d76b1f"
   },
   "outputs": [],
   "source": [
    "# perform edge detection, find contours in the edge map, and sort the\n",
    "# resulting contours from left-to-right\n",
    "edged = cv2.Canny(blurred, 0, 255)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(edged, cmap=cm.gray)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cCv-tg8VPXOT",
    "outputId": "c9c8d4c7-e323-4ac5-c8e5-e1823ff3f633"
   },
   "outputs": [],
   "source": [
    "contours = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "print('%d contours detected' % len(contours))\n",
    "\n",
    "# grab the bounding boxes of each contour\n",
    "bounding_boxes = [cv2.boundingRect(c) for c in contours]\n",
    "\n",
    "# sort the contours from top-left to bottom-right\n",
    "contours, bounding_boxes = zip(*sorted(zip(contours, bounding_boxes), key=lambda c: c[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "wfTw_uEyOuJ4",
    "outputId": "bdbde588-a0f3-4ccc-86da-d4f9d616211c"
   },
   "outputs": [],
   "source": [
    "# loop over the predictions and bounding box locations together\n",
    "for i in range(len(bounding_boxes)):\n",
    "    (x, y, w, h) = bounding_boxes[i]\n",
    "    # draw the bounding box on the image\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "# show the image\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byd4BQldJMaK",
    "outputId": "144f9b7a-f706-4e78-e862-03b75ebb5c39"
   },
   "outputs": [],
   "source": [
    "# list of characters to process\n",
    "chars = []\n",
    "\n",
    "# loop over the contours\n",
    "for c in contours:\n",
    "    # compute the bounding box of the contour\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    print(x, y, w, h)\n",
    "\n",
    "    # filter out bounding boxes, ensuring they are neither too small or too large\n",
    "    #if (w < 10 or w > 200 or h < 100 or h > 200):  # image 8\n",
    "    if (w < 25 or w > 200 or h < 30 or h > 100):  # image 9\n",
    "      continue\n",
    "\n",
    "    # extract the character \n",
    "    roi = gray[y:y + h, x:x + w]\n",
    "\n",
    "    # threshold and inverse the character\n",
    "    thresh = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    (tH, tW) = thresh.shape\n",
    "\n",
    "    # resize to 32 pixels\n",
    "    if tW > tH:\n",
    "      thresh = cv2.resize(thresh, (32, int(tH * 32 / tW)))\n",
    "    else:\n",
    "      thresh = cv2.resize(thresh, (int(tW * 32 / tH), 32))\n",
    "    print('resized to ', thresh.shape)\n",
    "\n",
    "    # pad the image to 32 x 32\n",
    "    (tH, tW) = thresh.shape\n",
    "    dX = int(max(0, 32 - tW) / 2.0)\n",
    "    dY = int(max(0, 32 - tH) / 2.0)\n",
    "    padded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
    "      left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
    "      value=(0, 0, 0))\n",
    "    padded = cv2.resize(padded, (32, 32))\n",
    "    \n",
    "    # prepare the image to be processed by the model\n",
    "    padded = padded.astype('float32') / 255.0\n",
    "    padded = np.expand_dims(padded, axis=-1)\n",
    "\n",
    "    # update our list of characters that will be OCR'd\n",
    "    chars.append((padded, (x, y, w, h)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1B-PnhUDh9xo",
    "outputId": "1982786d-709b-4377-bd38-36e36b33954c"
   },
   "outputs": [],
   "source": [
    "# put all characters in a single array to be processed by the model\n",
    "characters = np.array([c[0] for c in chars], dtype='float32')\n",
    "print(characters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "Wdj125ZLjO00",
    "outputId": "44458cb8-a889-4e7d-906e-7ca7c9a178b2"
   },
   "outputs": [],
   "source": [
    "i = 4\n",
    "plt.imshow(np.squeeze(characters[i]), cmap=cm.gray)\n",
    "label = labelNames[model.predict(np.expand_dims(characters[i], axis=0)).argmax(axis=1)[0]]\n",
    "plt.title('prediction: %s' % label)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dvw1Mvv0h4h6"
   },
   "outputs": [],
   "source": [
    "# now perform OCR on the characters using the model\n",
    "predictions = model.predict(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "T30yrYW8kIO0",
    "outputId": "96ff5851-2116-43d6-fc3b-5488c56c9311"
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "print(predictions[i])\n",
    "labelNames[predictions[i].argmax(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "id": "i_4z01dadBMs",
    "outputId": "2a715a6f-a4c5-4ee4-9328-609265e48a1e"
   },
   "outputs": [],
   "source": [
    "# loop over the predictions and bounding box locations together\n",
    "for prediction, (x, y, w, h) in zip(predictions, [c[1] for c in chars]):\n",
    "\n",
    "    # find the index of the label with the largest probability\n",
    "    i = prediction.argmax(axis=0)\n",
    "    prob = prediction[i]\n",
    "\n",
    "    # extract the label\n",
    "    label = labelNames[i]\n",
    "\n",
    "    # draw the prediction on the image\n",
    "    print(\"[INFO] {} - {:.2f}%\".format(label, prob * 100))\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.putText(image, label, (x + w // 2, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(10, 8)) \n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "2c9q4if0dEMD",
    "outputId": "8e5051d3-57f2-4f03-8313-8fbd6a400ef5"
   },
   "outputs": [],
   "source": [
    "labelNames[model.predict(np.expand_dims(padded, axis=0)).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yiX1R3Wifzwu",
    "outputId": "c58c990f-c9db-4983-dd04-85832f90e9bb"
   },
   "outputs": [],
   "source": [
    "labelNames.index('B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R45a-GrMIwKj",
    "outputId": "d6897793-4031-4da1-859e-6d2bf4cc91f0"
   },
   "outputs": [],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RtkxtvLI61V"
   },
   "outputs": [],
   "source": [
    "indices_A = np.where(testY[:, labelNames.index('A')])\n",
    "indices_B = np.where(testY[:, labelNames.index('B')])\n",
    "indices_I = np.where(testY[:, labelNames.index('I')])\n",
    "indices_M = np.where(testY[:, labelNames.index('M')])\n",
    "indices_N = np.where(testY[:, labelNames.index('N')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "RGwQoibnJGtz",
    "outputId": "049f2736-e42a-4115-d1f9-2b900687f67d"
   },
   "outputs": [],
   "source": [
    "# show examples of B in the test set\n",
    "images = []\n",
    "\n",
    "# randomly select a few testing characters\n",
    "for i in np.random.choice(indices_N[0], size=(49,)):\n",
    "    # classify the character\n",
    "    # extract the image from the test data and initialize the text\n",
    "    image = (testX[i] * 255).astype('uint8')\n",
    "    image = cv2.merge([image] * 3)\n",
    "    images.append(image)\n",
    "\n",
    "mosaic = image_mosaic(images, (96, 96), (7, 7))[0]\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(mosaic)\n",
    "plt.title('OCR Results')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-dlHs_2JNu0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OCR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
