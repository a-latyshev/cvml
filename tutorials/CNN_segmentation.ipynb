{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Session : Image segmentation\n",
    "\n",
    "The objective of this practical session is to perform the segmentation of noisy images of disks using the Context Aggregation Network introduced by Yu and Koltun in 2015.\n",
    "\n",
    "Yu, F., & Koltun, V. (2015). Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv:1511.07122."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the notebook using Google Colab:\n",
    "1. Go to Google Colab: https://colab.research.google.com/\n",
    "2. File -> Upload Notebook\n",
    "3. Upload the notebook \n",
    "4. In Edit -> Notebook Setting, select a gpu as hardware accelerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data generation\n",
    "\n",
    "The code below allows to simulate images of disks with distinct gray levels. The images are $64 \\times 64$ pixels images encoded on 8 bites. An average of $\\theta = 5$ disks are randomly generated in each image. The radii of the disks are sampled from independent normal distributions with mean $4$ pixels and standard deviation $0.5$ pixel. The gray level of each disk is drawn randomly from an uniform distribution between $15$ and $200$.\n",
    "White noise with standard deviation $\\sigma = 30$ pixels is then added to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Generator:\n",
    "\n",
    "    \"\"\"\n",
    "    Class used to generate synthetic images\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "\n",
    "    nx, ny: ints\n",
    "       shape of the synthetic image\n",
    "    theta: float\n",
    "       average number of disks per image\n",
    "    rmean: float\n",
    "       average radius of the disks\n",
    "    rstd: float\n",
    "       standard deviation of the radii\n",
    "    vmin, vmax: ints\n",
    "       minimal/maximal gray level of the disks\n",
    "    sigma: float\n",
    "       standard deviation of the noise\n",
    "    img: numpy array\n",
    "       synthetic image\n",
    "    img_truth: numpy array\n",
    "       ground truth image\n",
    "    ndisks: int\n",
    "       number of disks\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, theta, rmean, rstd, vmin, vmax, sigma):\n",
    "\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        size: ints\n",
    "           shape (nx, ny) of the synthetic image\n",
    "        theta: float\n",
    "           average number of disks per image\n",
    "        rmean: float\n",
    "           average radius of the disks\n",
    "        rstd: float\n",
    "           standard deviation of the radii\n",
    "        vmin, vmax: ints\n",
    "           minimal/maximal gray level of the disks\n",
    "        sigma: float\n",
    "           standard deviation of the noise\n",
    "        \"\"\"\n",
    "\n",
    "        self.nx, self.ny = size\n",
    "        self.theta = theta\n",
    "        self.rmean, self.rstd = rmean, rstd\n",
    "        self.vmin, self.vmax = vmin, vmax\n",
    "        self.sigma = sigma\n",
    "\n",
    "        self.img = np.zeros((self.nx, self.ny))\n",
    "        self.img_truth = np.zeros((self.nx, self.ny))\n",
    "\n",
    "\n",
    "    def generate(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Generate a synthetic image\n",
    "        \"\"\"\n",
    "\n",
    "        x = np.linspace(0, self.nx-1, self.nx)\n",
    "        y = np.linspace(0, self.ny-1, self.ny)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "        self.ndisks = np.random.poisson(self.theta)\n",
    "\n",
    "        for n in range(self.ndisks):\n",
    "\n",
    "            xc = np.random.uniform(0, self.nx)\n",
    "            yc = np.random.uniform(0, self.ny)\n",
    "            r = np.random.normal(loc=self.rmean, scale=self.rstd)\n",
    "            v = np.random.uniform(self.vmin, self.vmax)\n",
    "\n",
    "            mask = (np.power(xx - xc, 2) + np.power(yy - yc, 2) - r**2 < 0)\n",
    "            self.img[mask] = v\n",
    "            self.img_truth[mask] = 1\n",
    "\n",
    "        noise = self.sigma * np.random.randn(self.nx, self.ny)\n",
    "        self.img = np.clip(self.img + noise, 0, 255)\n",
    "        return self.img, self.img_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_channels = 64, 64, 1\n",
    "size = (img_rows, img_cols)\n",
    "theta = 5\n",
    "rmean = 4\n",
    "rstd = 0.5\n",
    "vmin = 15\n",
    "vmax = 200 \n",
    "sigma = 30\n",
    "\n",
    "# Image generation\n",
    "synthetic_img = Data_Generator(size, theta, rmean, rstd, vmin, vmax, sigma)\n",
    "img, img_truth = synthetic_img.generate()\n",
    "\n",
    "# Display the generated images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5),sharex=True,sharey=True)\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_truth)\n",
    "for a in ax.ravel():\n",
    "    a.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question 1*. Use the code of the previous cell to generate a dataset of 2000 training image and 200 validation images. The dataset must be at a format compatible with keras (ex: numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 2000\n",
    "X_train, Y_train = [], []\n",
    "\n",
    "# Insert your code here\n",
    "\n",
    "print('Generation of the training set completed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_val_samples = 200\n",
    "X_val, Y_val = [], []\n",
    "\n",
    "# Insert your code here\n",
    "\n",
    "print('Generation of the validation set completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below display one of the training image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 4\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5),sharex=True,sharey=True)\n",
    "ax[0].imshow(X_train[index, :, :])\n",
    "ax[1].imshow(Y_train[index, :, :])\n",
    "for a in ax.ravel():\n",
    "    a.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network Architecture\n",
    "\n",
    "We use the Context Aggregation Network to perform the image segmentation. The particularity of this convolutional neural network is that it gradually aggregates contextual information without losing resolution through the use of dilated convolutions, whose field of view increases exponentially over the network layers. \n",
    "\n",
    "The input image is normalized and goes through a set of layers $\\{L^1, \\cdots, L^d\\}$. The output of the network is constituted of an image with one channel corresponding to the segmentation mask for the disks.\n",
    "\n",
    "Each block $L^s$, $s\\in [\\![2,d-1]\\!]$ is made of \n",
    "1. a dilated convolution, with receptive field $ 3\\times 3 $, depth $24$, dilation parameter $r_s=2^s$ and stride $1$, \n",
    "2. a batch normalization layer\n",
    "3. a leaky rectifier linear unit (LReLU), defined as\n",
    "$ \\Phi(x) = \\max(0.2 x, x) $\n",
    "as activation function. \n",
    "Padding is applied to ensure that the output of the block has the same size as the input.\n",
    "\n",
    "The final block of the network is composed of a 2D convolution with receptive field $1 \\times 1$, depth $1$, stride $1$, dilation $1$ and uses a Sigmoid activation function.\n",
    "\n",
    "*Question 2.* Implement the CAN architecture with Keras. Do not forget to include the normalization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU\n",
    "\n",
    "\n",
    "def make_model(input_shape, nb_modules):\n",
    "    \n",
    "    \"\"\"\n",
    "    Creates the network architecture\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    input shape: tuple of ints\n",
    "        shape of the input image\n",
    "    nb_modules: int\n",
    "        number of module\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    out: Keras model\n",
    "        Keras model for the CAN architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Insert your code here\n",
    "\n",
    "input_shape = (64, 64, 1)\n",
    "nb_layers = 6\n",
    "model = make_model(input_shape, nb_layers)\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model\n",
    "\n",
    "The code in the following cell trains the neural network architecture and plot the evolution of the training loss/validation loss according to the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=10,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** #####################################\"\n",
    "print(\"Best validation loss: %.5f\" % (np.min(history.history['val_loss'])))\n",
    "print(\"at: %d\" % np.argmin(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='train')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='val')\n",
    "plt.title('Training performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim(0.0, 0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Test the model\n",
    "\n",
    "*Question 3*. Generate a dataset of 10 test images and test the result of the algorithm on these images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test_samples = 10\n",
    "X_test, Y_test = [], []\n",
    "\n",
    "# Insert your code here\n",
    "\n",
    "print('Generation of the test set completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
