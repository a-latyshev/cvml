{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP: Segmentation par réseau de neurones convolutionnel\n",
    "\n",
    "L'objectif du présent TP est d'entraîner un réseau de neurone à identifier le centre de particules sur des images obtenues dans des expériences de rhéologie. Le TP est implémenté dans le langage PyTorch, et l'architecture du réseau décrite dans le document PDF attaché. On s'intéressera à plusieurs aspects de l'implémentation:\n",
    "- le chargement et la visualisation des données d'entraînement (Partie 1)\n",
    "- l'implémentation du réseau (Partie 2)\n",
    "- l'entraînement du réseau (Partie 3)\n",
    "\n",
    "On visualisera enfin les résultats obtenus par le réseau sur la base de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie 1: Données\n",
    "\n",
    "Pour entraîner le réseau de neurones, nous disposons d'une base de données de 320 images, réparties en:\n",
    "- 220 images d'entraînement\n",
    "- 32 images de validation\n",
    "- 64 images de test\n",
    "\n",
    "Toutes les images ont une taille de 500 pixels par 500 pixels. La vérité terrain consiste en une image contenant un masque de segmentation et en une image contenant des marqueurs du centre des particules à détecter.\n",
    "\n",
    "Afin d'augmenter artificiellement la taille des données, une pratique courante consiste à appliquer des transformations diverses aux images: distorsion d'histogramme, crops aléatoires, etc. Le code ci-dessous permet de charger des images d'entraînement et de validation, et d'appliquer certaines transformations aux images.\n",
    "\n",
    "*Question 1.1: Lancer le code et modifier les différentes opérations d'augmentation de données pour visualiser les images sur lesquelles le réseau est entraîné.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-60f4795f4881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root_dir = './dataset'\n",
    "train_dir = 'train'\n",
    "val_dir = 'val'\n",
    "target_dir = 'labels'\n",
    "\n",
    "# Training set\n",
    "train_dataset = SegmentationDataset(\n",
    "    root_dir= root_dir,\n",
    "    input_dir= train_dir,\n",
    "    target_dir= target_dir,\n",
    "    transform=transforms.Compose([\n",
    "        RandomCrop(200),\n",
    "        Distort(),\n",
    "        SetTarget(),\n",
    "        Normalize(),\n",
    "        ToTensor()]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 1,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(trainloader):\n",
    "                \n",
    "        input_img = sample['input'][0]\n",
    "        segm_true = sample['target'][0]\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "        ax[0].imshow(np.transpose(input_img, (2, 1, 0)), cmap = 'gray')\n",
    "        ax[0].set_title('Input image')\n",
    "        \n",
    "        ax[1].imshow(np.transpose(segm_true[0]), cmap = 'gray')\n",
    "        ax[1].set_title('Segmentation mask')\n",
    "        \n",
    "        ax[2].imshow(np.transpose(segm_true[1]))\n",
    "        ax[2].set_title('particle markers')\n",
    "\n",
    "        for a in ax.ravel():\n",
    "            a.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        if(i > 5):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie 2: Implémentation du réseau de neurone\n",
    "\n",
    "Le réseau de neurone que nous utilisons s'appuie sur une structure de base constituée d'une couche de convolution, d'une non-linéarité de type RELU, et d'un module d'*adaptative batch normalization*, qui consiste à appliquer l'opération suivante au tenseur d'entrée:\n",
    "\n",
    "$$\n",
    "y = a BN(x) + bx,\n",
    "$$\n",
    "\n",
    "BN étant ici l'opérateur de *batch normalization*, donné par la formule mathématique suivante:\n",
    "\n",
    "$$\n",
    "BN(x) = \\gamma \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} + \\beta\n",
    "$$\n",
    "\n",
    "*Question 2.1:* En utilisant la fonction BatchNorm2D déjà implémentée dans PyTorch, implémenter une classe permettant de définir une couche d'adaptative batch normalization en vous appuyant sur la structure de code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveBatchNorm2d(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Adaptative batch normalization implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, num_features, momentum=.1, eps=1e-5, affine=True):\n",
    "\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "\n",
    "        An adaptative batch normalization layer takes as input a tensor x and outputs a tensor y.\n",
    "\n",
    "        The shape of the input tensor is BxCxWxH where B is the number of images in each batch,\n",
    "        C the number of features maps, W the width of the image and H the height of the image, \n",
    "        respectively.\n",
    "\n",
    "        :param num_features: Number of features map\n",
    "        :param momentum: Parameter used by the batch normalization layer to compute the statistics\n",
    "        :param eps: Value added to the denominator for ensuring stability\n",
    "        :param affine: When set to True, indicates that the batch normalization \n",
    "         layer has learnable affine parameters.\n",
    "\n",
    "        :type num_features: int\n",
    "        :type momentum: float\n",
    "        :type eps: float\n",
    "        :type affine: Boolean\n",
    "\n",
    "        ..seealso:: Pytorch documentation for nn.BatchNorm2D\n",
    "        \"\"\"\n",
    "\n",
    "        super(AdaptiveBatchNorm2d, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(num_features, momentum, eps, affine)\n",
    "        tens_a = torch.FloatTensor(1, 1, 1, 1)\n",
    "        tens_b = torch.FloatTensor(1, 1, 1, 1)\n",
    "        tens_a[0, 0, 0, 0] = 1\n",
    "        tens_b[0, 0, 0, 0] = 0\n",
    "        self.a = nn.Parameter(tens_a)\n",
    "        self.b = nn.Parameter(tens_b)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass in the adaptative batch normalization layer\n",
    "        \n",
    "        .. math::\n",
    "        y = a BN(x) + bx\n",
    "\n",
    "        where BN is a batch normalization layer, and a and b are learneable parameters.\n",
    "\n",
    "        :param x: Input tensor, with size BxCxWxH\n",
    "        :type x: PyTorch tensor\n",
    "\n",
    "        :return: Transformed tensor\n",
    "        :rtype: PyTorch tensor\n",
    "        \"\"\"\n",
    "\n",
    "        return self.a * x + self.b * self.bn(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question 2.2:* En utilisant les modules nn.Conv2d et nn.LeakyReLU déjà implémentés dans PyTorch, coder une classe permettant de définir une couche de convolutions dilatée en vous appuyant sur la structure de code ci-dessous. L'utilisateur devra pouvoir spécifier la profondeur des tenseurs d'entrée et de sortie, ainsi que la taille de la dilatation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseBlock(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Convolution module implementation: 2D dilated Convolution \n",
    "    followed by a batch normalization layer and a leaky RELU\n",
    "    activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, s):\n",
    "\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        :param in_channels: Shape of the input tensor\n",
    "        :param out_channes: Shape of the output tensor\n",
    "        :param s: Dilation scale\n",
    "\n",
    "        :type in_channels: int\n",
    "        :type out_channels: int\n",
    "        :type s: int\n",
    "        \"\"\"\n",
    "\n",
    "        super(BaseBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "          padding = 2**(s-1), dilation = 2**(s-1), bias=True)\n",
    "\n",
    "        self.conv_abn = AdaptiveBatchNorm2d(out_channels)\n",
    "        self.LReLU = nn.LeakyReLU(0.2, inplace = True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass in the convolution module\n",
    "\n",
    "        :param x: Input tensor, with size BxCxWxH batch canal width height\n",
    "        :type x: PyTorch tensor\n",
    "\n",
    "        :return: Transformed tensor\n",
    "        :rtype: PyTorch tensor\n",
    "        \"\"\"\n",
    "\n",
    "        return self.LReLU(self.conv_abn(self.conv(x)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question 2.3:* A partir des deux classes que vous venez d'implémenter, construisez le réseau de neurone proposé pour la détection des particules. L'utilisateur devra en particulier pouvoir spécifier le nombre de modules de base dans le réseau, ainsi que le nombre de canaux des tenseurs des couches intermédiaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Implementation of the neural network architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d=7, w=24):\n",
    "\n",
    "        \"\"\"\n",
    "        Class constructor\n",
    "\n",
    "        :param d: number of blocks in the architecture\n",
    "        :type d: int\n",
    "        \"\"\"\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        self.first_layer = BaseBlock(3, w, 1)  #3 input channels\n",
    "        self.intermediate_layers = nn.ModuleList([BaseBlock(w, w, s) for s in range(2, d)])   \n",
    "        self.final_layer = nn.Conv2d(w, 2, kernel_size=1, bias=True)  #2 output channels\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass in the convolutional network\n",
    "\n",
    "        :param x: Input tensor with size Bx3xWxH\n",
    "         (B: batch size, 3: number of channels, W: image width, H: image height)\n",
    "        :type x: PyTorch tensor\n",
    "\n",
    "        :return: Transformed tensor\n",
    "        :rtype: PyTorch Tensor\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.first_layer(x)\n",
    "        for l in self.intermediate_layers:\n",
    "            x = l(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        Size of the flattened tensor\n",
    "\n",
    "        :param x: Input tensor with size BxCxWxH\n",
    "         (B: batch size, C: number of channels, W: image width, H: image height)\n",
    "        :type x: PyTorch tensor\n",
    "\n",
    "        :return: CxWxH\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "\n",
    "        size = x.size()[1:] \n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie 3: entraînement du réseau \n",
    "\n",
    "*Question 3.1:* Pour chaque batch, implémenter dans les fonctions \"train\" et \"test\" ci-dessous:\n",
    "1. la propagation directe des images du batch dans le réseau (train et test)\n",
    "2. la retro-propagation du gradient (train)\n",
    "3. la mise à jour des poids du réseau (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    \"\"\"\n",
    "    Train the network\n",
    "\n",
    "    :param epoch: current epoch\n",
    "    :type epoch: int\n",
    "    \"\"\"\n",
    "\n",
    "    epoch_loss = []\n",
    "    for i, sample in enumerate(trainloader):\n",
    "                \n",
    "        # Load batch\n",
    "        input_img = sample['input'].to(device)\n",
    "        segm_true = sample['target'].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward/Backward pass\n",
    "        outputs = net(input_img)\n",
    "        loss = criterion(outputs, segm_true)\n",
    "        loss.backward()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        # Weights update\n",
    "        optimizer.step()\n",
    "\n",
    "    # Write the training loss in a .dat file\n",
    "    training_loss = np.mean(np.array(epoch_loss))\n",
    "    print('Training loss: ' + str(training_loss))\n",
    "    with open('training_loss.dat', \"a\") as f:\n",
    "        f.write('%d %.15f\\n' % (epoch + 1, training_loss))\n",
    "\n",
    "    # Save weights\n",
    "    torch.save(net.state_dict(), os.path.join(weights_path, str(epoch) + '.pth'))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def validate(epoch):\n",
    "\n",
    "    \"\"\"\n",
    "    Test the network on the validation set\n",
    "\n",
    "    :param epoch: current epoch\n",
    "    :type epoch: int\n",
    "    \"\"\"\n",
    "    epoch_loss = []\n",
    "    for i, sample in enumerate(validationloader):\n",
    "                \n",
    "        # Load batch\n",
    "        input_img = sample['input'].to(device)\n",
    "        segm_true = sample['target'].to(device)\n",
    "\n",
    "        # Forward/Backward pass\n",
    "        outputs = net(input_img)\n",
    "        loss = criterion(outputs, segm_true)\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "    validation_loss = np.mean(np.array(epoch_loss))\n",
    "    print('Validation loss: ' + str(validation_loss))\n",
    "    with open('val_loss.dat', \"a\") as f:\n",
    "        f.write('%d %.15f\\n' % (epoch + 1, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question 3.2:* Implémenter l'entraînement du réseau et entraîner le réseau avec des valeurs de $d=5$, $d=6$ et $d=7$. Tracer la fonction de perte pour l'entraînement et la validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and architecture parameters\n",
    "d = 7\n",
    "w = 24\n",
    "dict_weights = None\n",
    "batch_size = 16\n",
    "start_epoch = 0\n",
    "num_epochs = 80\n",
    "learning_rate = 0.005\n",
    "divide = 2.  \n",
    "each = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training/validation data\n",
    "train_dataset = SegmentationDataset(\n",
    "    root_dir= root_dir,\n",
    "    input_dir= train_dir,\n",
    "    target_dir= target_dir,\n",
    "    transform=transforms.Compose([\n",
    "      RandomCrop(128),\n",
    "      Distort(),\n",
    "      SetTarget(),\n",
    "      Normalize(),\n",
    "      ToTensor()]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 0)\n",
    "\n",
    "# Test set\n",
    "val_dataset = SegmentationDataset(\n",
    "    root_dir= root_dir,\n",
    "    input_dir= val_dir,\n",
    "    target_dir= target_dir,\n",
    "    transform=transforms.Compose([\n",
    "       RandomCrop(128),\n",
    "       SetTarget(),\n",
    "       Normalize(),\n",
    "       ToTensor()]))\n",
    "\n",
    "validationloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)\n",
    "    \n",
    "# Constructs the neural network\n",
    "net = Net(d, w)\n",
    "net.to(device)\n",
    "if(dict_weights != None):\n",
    "    net.load_state_dict(torch.load(dict_weights))\n",
    "\n",
    "weights_path = './weights'\n",
    "loss_path = './output'\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "if not os.path.exists(loss_path):\n",
    "    os.makedirs(loss_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        if (epoch % each == 0):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] /= divide\n",
    "                \n",
    "        train(epoch)\n",
    "        validate(epoch)\n",
    "        \n",
    "train_err = np.loadtxt(\"training_loss.dat\")[:, 1]\n",
    "val_err = np.loadtxt(\"val_loss.dat\")[:, 1]\n",
    "plt.figure()\n",
    "plt.plot(train_err, label='train')\n",
    "plt.plot(val_err, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = np.loadtxt(\"training_loss.dat\")[100:, 1]\n",
    "val_err = np.loadtxt(\"val_loss.dat\")[100:, 1]\n",
    "plt.figure()\n",
    "plt.plot(train_err, label='train')\n",
    "plt.plot(val_err, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_err = np.loadtxt(\"training_loss.dat\")[100:, 1]\n",
    "val_err = np.loadtxt(\"val_loss.dat\")[100:, 1]\n",
    "plt.figure()\n",
    "plt.plot(train_err, label='train')\n",
    "plt.plot(val_err, label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "print(np.argmin(val_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie 4: test du réseau \n",
    "\n",
    "*Question 4.1:* Le code ci-dessous permet de visualiser les résultats du réseau de neurones sur la base de test. En vous appuyant sur l'erreur de validation, sélectionnez un des fichiers de poids que vous avez obtenus durant l'entraînement et lancez l'évaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img, output, target):\n",
    "\n",
    "    img = (255*img.data.cpu().numpy()[0]).astype('int')\n",
    "    output = (255*output.data.cpu().numpy()[0]).astype('int')\n",
    "    target = (255*target.data.cpu().numpy()[0]).astype('int')\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize=(10, 5), sharex=True, sharey=True)\n",
    "\n",
    "    target=np.transpose(target, (2, 1, 0) )\n",
    "    output=np.transpose(output, (2, 1, 0) )\n",
    "\n",
    "    # Gaussian mask\n",
    "    GaussMask=output[...,1]\n",
    "    from skimage.feature import peak_local_max\n",
    "    from skimage.filters import gaussian\n",
    "    GaussMask = gaussian(GaussMask, sigma = 2)\n",
    "    GaussMask = ( GaussMask / np.max(GaussMask) ) * 255\n",
    "    coordinates = peak_local_max(GaussMask,min_distance=7,threshold_abs=100)\n",
    "\n",
    "    #target segmentation\n",
    "    ax[0].set_title(\"Segmentation mask\")\n",
    "    ax[0].imshow(output[...,0]>180.)\n",
    "\n",
    "    #input image\n",
    "    ax[1].set_title(\"Input image\")\n",
    "    ax[1].imshow(np.transpose(img, (2, 1, 0)))\n",
    "\n",
    "    #Network segmentation\n",
    "    ax[2].set_title(\"Network segmentation mask\")\n",
    "    ax[2].imshow(np.transpose(img, (2, 1, 0)))  #>210\n",
    "    ax[2].plot(coordinates[:, 1], coordinates[:, 0], 'b.')\n",
    "\n",
    "    for a in ax.ravel():\n",
    "        a.set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "test_dir = 'test'\n",
    "\n",
    "# Select a device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "dict_weights = './weights/199.pth'\n",
    "batch_size = 1\n",
    "\n",
    "# Test set\n",
    "test_dataset = SegmentationDataset(\n",
    "    root_dir= root_dir,\n",
    "    input_dir= test_dir,\n",
    "    target_dir= target_dir,\n",
    "    transform=transforms.Compose([\n",
    "       Crop(256),\n",
    "       SetTarget(),\n",
    "       Normalize(),\n",
    "       ToTensor()]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    num_workers = 0)\n",
    "\n",
    "# Constructs the neural network\n",
    "net = Net(d, w)\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(dict_weights))\n",
    "\n",
    "for i, sample in enumerate(testloader):\n",
    "                \n",
    "    # Load batch\n",
    "    input_img = sample['input'].to(device)\n",
    "    segm_true = sample['target'].to(device)\n",
    "\n",
    "    # Forward/Backward pass\n",
    "    outputs = net(input_img)\n",
    "\n",
    "    # Display\n",
    "    display(input_img, outputs, segm_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
